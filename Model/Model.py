import re
import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import defaultdict
from sklearn.neighbors import NearestNeighbors
from sqlalchemy import create_engine
from Model.synonym_finder import find_user_ingredients

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
current_dir = os.path.dirname(os.path.abspath(__file__))
db_path = os.path.join(current_dir, '..', 'recipes.db')
engine = create_engine(f'sqlite:///{db_path}')

recipe_names = []
recipes_texts = []
recipes_full = []
synonyms = {}
all_ingredients = []
vectorizer = None
X = None
knn = None


def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    global recipe_names, recipes_texts, recipes_full

    try:
        print(f"[DEBUG] –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ –±–∞–∑–µ –ø–æ –ø—É—Ç–∏: {db_path}")
        data = pd.read_sql('SELECT name, ingredients, instructions FROM recipes', engine)

        if data.empty:
            raise ValueError("–¢–∞–±–ª–∏—Ü–∞ 'recipes' –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

        print(f"[DEBUG] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Ä–µ—Ü–µ–ø—Ç–æ–≤")
        print("[DEBUG] –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:", data.iloc[0] if len(data) > 0 else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

        recipe_names = data['name'].tolist()
        recipes_texts = data['ingredients'].tolist()
        recipes_full = data.to_dict('records')

    except Exception as e:
        print(f"[ERROR] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise


def generate_synonyms():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤"""
    synonym_dict = defaultdict(list)

    synonym_groups = [
        ['–∫–∞—Ä—Ç–æ—Ñ–µ–ª—å', '–∫–∞—Ä—Ç–æ—à–∫–∞'],
        ['–ø–æ–º–∏–¥–æ—Ä', '—Ç–æ–º–∞—Ç'],
        ['–ª—É–∫', '—Ä–µ–ø—á–∞—Ç—ã–π –ª—É–∫'],
        ['–∫—É—Ä–∏—Ü–∞', '–∫—É—Ä–∏–Ω–æ–µ —Ñ–∏–ª–µ'],
        ['—è–π—Ü–æ', '—è–π—Ü–∞'],
        ['–ø–µ—Ä–µ—Ü', '–±–æ–ª–≥–∞—Ä—Å–∫–∏–π –ø–µ—Ä–µ—Ü']
    ]

    for group in synonym_groups:
        main_ing = group[0]
        for syn in group[1:]:
            synonym_dict[main_ing].append(syn)

    return synonym_dict


def parse_ingredients(ingredients_str):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ —Å –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞–º–∏"""
    ingredients = []
    for ing in re.split(r'[,;]', ingredients_str):
        ing = re.sub(r'\d+[.,]?\d*', '', ing).strip().lower()
        ing = re.sub(r'\(.*?\)', '', ing).strip()
        if ing:
            ingredients.append(ing)
    return ingredients


def normalize_ingredient(ing):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞ —Å —É—á–µ—Ç–æ–º —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""
    ing = ing.lower().strip()
    for main_word, syns in synonyms.items():
        if ing == main_word or ing in syns:
            return main_word
    return ing


def prepare_model():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    global all_ingredients, vectorizer, X, knn

    all_ingredients_set = set()
    for text in recipes_texts:
        parsed = parse_ingredients(text)
        normalized = [normalize_ingredient(ing) for ing in parsed]
        all_ingredients_set.update(normalized)

    all_ingredients = list(all_ingredients_set)

    vectorizer = TfidfVectorizer(vocabulary=all_ingredients, binary=True)

    train_texts = []
    for text in recipes_texts:
        parsed = parse_ingredients(text)
        normalized = [normalize_ingredient(ing) for ing in parsed]
        train_texts.append(' '.join(normalized))

    X = vectorizer.fit_transform(train_texts)
    knn = NearestNeighbors(n_neighbors=5, metric='cosine')
    knn.fit(X)


def recommend_recipes(user_input, return_full=True):
    synonyms = generate_synonyms()
    load_data()
    prepare_model()
    user_ingredients = find_user_ingredients(user_input, all_ingredients, synonyms)
    print(f"[DEBUG] –ù–∞–π–¥–µ–Ω—ã –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {user_ingredients}")

    results = []
    for idx, ingredients in enumerate(recipes_texts):
        recipe_ings = parse_ingredients(ingredients)
        common = set(user_ingredients) & set(recipe_ings)
        if common:
            results.append({
                'name': recipe_names[idx],
                'match_count': len(common),
                'ingredients': ingredients
            })

    return sorted(results, key=lambda x: -x['match_count'])[:3]


def format_recommendations(recommendations):
    synonyms = generate_synonyms()
    load_data()
    prepare_model()
    if not recommendations:
        return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ä–µ—Ü–µ–ø—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã."

    messages = []
    for recipe in recommendations:
        if not isinstance(recipe, dict):
            continue

        name = recipe['name']
        ingredients = recipe.get('ingredients', '')
        parsed_ingredients = parse_ingredients(ingredients)
        match_count = recipe.get('match_count', 0)

        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        try:
            match_percent = int((match_count / len(parsed_ingredients)) * 100) if parsed_ingredients else 0
        except ZeroDivisionError:
            match_percent = 0

        msg = f"üç≥ {name}\n"
        msg += f"üîπ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {match_percent}%\n"
        msg += f"üîπ –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {', '.join(parsed_ingredients[:3])}"
        if len(parsed_ingredients) > 3:
            msg += "..."

        messages.append(msg)

    return "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Ü–µ–ø—Ç—ã:\n\n" + "\n\n".join(messages)

